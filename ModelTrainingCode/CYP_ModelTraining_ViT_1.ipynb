{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_DATASET\"\n",
    "CLASSES = [\"BLIGHT\", \"BLAST\", \"BROWNSPOT\", \"HEALTHY\"]\n",
    "IMG_SIZE = (224, 224) # Common size for ViT-B/16\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load filepaths & labels ===\n",
    "all_filepaths, all_labels = [], []\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    aug_path = os.path.join(BASE_PATH, class_name, \"augmented\")\n",
    "    files = glob.glob(os.path.join(aug_path, \"*.jpg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.jpeg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.png\"))\n",
    "    all_filepaths.extend(files)\n",
    "    all_labels.extend([idx] * len(files))\n",
    "\n",
    "all_filepaths = np.array(all_filepaths)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: Train=19204, Val=2400, Test=2404\n"
     ]
    }
   ],
   "source": [
    "# === Create datasets ===\n",
    "def load_and_preprocess_image(filepath, label):\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0  # Normalize to [0, 1] for ViT\n",
    "    return img, tf.one_hot(label, len(CLASSES))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_filepaths, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024, seed=SEED)\n",
    "\n",
    "train_size = int(0.8 * len(all_filepaths))\n",
    "val_size = int(0.1 * len(all_filepaths))\n",
    "test_size = len(all_filepaths) - train_size - val_size\n",
    "\n",
    "train_ds = dataset.take(train_size).map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = dataset.skip(train_size).take(val_size).map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = dataset.skip(train_size + val_size).map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Dataset sizes: Train={len(train_ds)*BATCH_SIZE}, Val={len(val_ds)*BATCH_SIZE}, Test={len(test_ds)*BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " vit_feature_extractor (Kera  (None, 1000)             86567656  \n",
      " sLayer)                                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,571,660\n",
      "Trainable params: 4,004\n",
      "Non-trainable params: 86,567,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# === Build Model (Phase 1: Feature Extractor Frozen) ===\n",
    "# Use the new working ViT model from TensorFlow Hub\n",
    "vit_model_handle = \"https://www.kaggle.com/models/spsayakpaul/vision-transformer/TensorFlow2/vit-b16-classification/1\" # Corrected ViT feature extractor URL\n",
    "# model = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(\"https://www.kaggle.com/models/spsayakpaul/vision-transformer/TensorFlow2/vit-b16-classification/1\")\n",
    "# ])\n",
    "\n",
    "# Input layer for the images\n",
    "inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "# Load the ViT feature extractor\n",
    "# trainable=False freezes the weights of the ViT backbone\n",
    "vit_backbone = hub.KerasLayer(vit_model_handle, trainable=False, name='vit_feature_extractor')(inputs)\n",
    "\n",
    "# Add a classification head on top of the frozen ViT features\n",
    "x = Dropout(0.5)(vit_backbone)\n",
    "outputs = Dense(len(CLASSES), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), # Higher LR for new layers\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Computed class weights: {0: 1.3298476454293628, 1: 0.7029945819300044, 2: 0.8826530612244898, 3: 1.4438345864661655}\n"
     ]
    }
   ],
   "source": [
    "# === Learning Rate Logger Callback ===\n",
    "class LearningRateLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if hasattr(lr, '__call__'):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        if hasattr(lr, 'numpy'):\n",
    "            lr = lr.numpy()\n",
    "        print(f\"ðŸ“‰ Learning rate at epoch {epoch+1}: {lr:.6f}\")\n",
    "\n",
    "# === Compute class weights ===\n",
    "y_train_int = np.argmax(np.concatenate([labels.numpy() for _, labels in train_ds.unbatch().batch(BATCH_SIZE)]), axis=1)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(CLASSES)),\n",
    "    y=y_train_int\n",
    ")))\n",
    "print(\"âœ… Computed class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/vit_feature_extractor/StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADITYA DAS\\AppData\\Local\\Temp\\ipykernel_12996\\3391820251.py\", line 2, in <module>\n      history = model.fit(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 233, in call\n      if not self._has_training_argument:\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 234, in call\n      result = f()\nNode: 'model/vit_feature_extractor/StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node model/vit_feature_extractor/StatefulPartitionedCall}}]] [Op:__inference_train_function_41131]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Train ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLearningRateLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model/vit_feature_extractor/StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADITYA DAS\\AppData\\Local\\Temp\\ipykernel_12996\\3391820251.py\", line 2, in <module>\n      history = model.fit(\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 233, in call\n      if not self._has_training_argument:\n    File \"C:\\Users\\ADITYA DAS\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 234, in call\n      result = f()\nNode: 'model/vit_feature_extractor/StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node model/vit_feature_extractor/StatefulPartitionedCall}}]] [Op:__inference_train_function_41131]"
     ]
    }
   ],
   "source": [
    "# === Train ===\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[EarlyStopping(patience=4, restore_best_weights=True), LearningRateLogger()],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate ===\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASSES)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Phase 1 (ViT)')\n",
    "plt.show()\n",
    "\n",
    "# === Save ===\n",
    "SAVE_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_MODEL\\ViT_Phase1_CutMix_GridMask.h5\"\n",
    "model.save(SAVE_PATH)\n",
    "print(f\"âœ… Model saved at: {SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
