{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162daee0-7c58-4224-8b69-09054c8b2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet_phase2.py\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ffe3a-f1e2-4c5e-81e5-24676bb72e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure a consistent random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5e3ea-f26a-44a6-b0be-b226af206d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "BASE_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_DATASET\"\n",
    "CLASSES = [\"BLIGHT\", \"BLAST\", \"BROWNSPOT\", \"HEALTHY\"]\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60 # Typically more epochs for fine-tuning\n",
    "LEARNING_RATE = 1e-5 # Typically lower for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9d86b-ec0f-4003-933e-71ff2873ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedb4e0-f58c-46a6-b246-870d3afefc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Dataset ---\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels, transform=None, augment=False):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filepaths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.augment:\n",
    "            # Apply Color Jitter (as part of transform) and GridMask\n",
    "            image = np.array(image) # Convert to numpy for GridMask\n",
    "            image = grid_mask(image)\n",
    "            image = Image.fromarray(image) # Convert back to PIL for torchvision transforms\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df34255-25f5-421b-b9f7-268cabf574b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Augmentation Functions ---\n",
    "def color_jitter_transform():\n",
    "    return transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05)\n",
    "\n",
    "def grid_mask(img, d_min=50, d_max=100, ratio=0.5):\n",
    "    h, w, _ = img.shape\n",
    "    d = random.randint(d_min, d_max)\n",
    "    l = int(d * ratio)\n",
    "\n",
    "    mask = np.ones((h, w), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, h, d):\n",
    "        for j in range(0, w, d):\n",
    "            y1 = i\n",
    "            y2 = min(i + l, h)\n",
    "            x1 = j\n",
    "            x2 = min(j + l, w)\n",
    "\n",
    "            mask[y1:y2, x1:x2] = 0.0\n",
    "\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return img * mask\n",
    "\n",
    "def cutmix(images, labels, alpha=1.0):\n",
    "    batch_size = images.shape[0]\n",
    "    img_h, img_w = images.shape[2], images.shape[3]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha, size=batch_size)\n",
    "    rand_idx = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_images = images.clone()\n",
    "    mixed_labels = labels.clone()\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        curr_lam = lam[i]\n",
    "        \n",
    "        # Calculate bounding box for cut-and-paste\n",
    "        cut_rat = np.sqrt(1. - curr_lam)\n",
    "        cut_w = img_w * cut_rat\n",
    "        cut_h = img_h * cut_rat\n",
    "\n",
    "        cx = np.random.uniform(0, img_w)\n",
    "        cy = np.random.uniform(0, img_h)\n",
    "\n",
    "        x1 = int(cx - cut_w / 2)\n",
    "        y1 = int(cy - cut_h / 2)\n",
    "        x2 = int(cx + cut_w / 2)\n",
    "        y2 = int(cy + cut_h / 2)\n",
    "\n",
    "        x1 = np.clip(x1, 0, img_w)\n",
    "        y1 = np.clip(y1, 0, img_h)\n",
    "        x2 = np.clip(x2, 0, img_w)\n",
    "        y2 = np.clip(y2, 0, img_h)\n",
    "        \n",
    "        # Adjust lambda based on actual patch size\n",
    "        bb_area = (x2 - x1) * (y2 - y1)\n",
    "        lam_adjusted = 1.0 - (bb_area / (img_w * img_h))\n",
    "\n",
    "        mixed_images[i, :, y1:y2, x1:x2] = images[rand_idx[i], :, y1:y2, x1:x2]\n",
    "\n",
    "        # One-hot encode labels for mixing\n",
    "        label1_onehot = F.one_hot(labels[i], num_classes=len(CLASSES)).float()\n",
    "        label2_onehot = F.one_hot(labels[rand_idx[i]], num_classes=len(CLASSES)).float()\n",
    "        \n",
    "        mixed_labels[i] = lam_adjusted * label1_onehot + (1.0 - lam_adjusted) * label2_onehot\n",
    "    \n",
    "    return mixed_images, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe217e-cc1d-4170-ba02-a2c47ed8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load filepaths & labels ---\n",
    "all_filepaths, all_labels = [], []\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    aug_path = os.path.join(BASE_PATH, class_name, \"augmented\")\n",
    "    files = glob.glob(os.path.join(aug_path, \"*.jpg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.jpeg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.png\"))\n",
    "    all_filepaths.extend(files)\n",
    "    all_labels.extend([idx] * len(files))\n",
    "\n",
    "print(f\"âœ… Total images found: {len(all_filepaths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bb17b-0cb9-4dae-9229-89a768e794c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split data ---\n",
    "train_filepaths, val_filepaths, train_labels, val_labels = train_test_split(\n",
    "    all_filepaths, all_labels, test_size=0.2, random_state=SEED, stratify=all_labels\n",
    ")\n",
    "\n",
    "print(f\"âœ… Train samples: {len(train_filepaths)} | Val samples: {len(val_filepaths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fd22b-5f90-476c-938a-0e242ee46e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transforms (including EfficientNet specific preprocessing) ---\n",
    "train_transform = transforms.Compose([\n",
    "    color_jitter_transform(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65fc69-6653-4173-8451-6afcf0aa258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Datasets and DataLoaders ---\n",
    "train_dataset = PlantDiseaseDataset(train_filepaths, train_labels, transform=train_transform, augment=True)\n",
    "val_dataset = PlantDiseaseDataset(val_filepaths, val_labels, transform=val_transform, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5a713-9185-4cb0-87d8-b81403007f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EfficientNetB0 Model for Phase 2 ---\n",
    "class EfficientNetB0_Phase2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetB0_Phase2, self).__init__()\n",
    "        self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1') # Load pre-trained weights\n",
    "\n",
    "        # IMPORTANT: Do NOT freeze layers here. They will be unfrozen.\n",
    "\n",
    "        # Replace the classifier head (must match Phase 1's head structure)\n",
    "        num_ftrs = self.backbone.classifier[1].in_features\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        # Re-assign the classifier to the backbone model for seamless forward pass\n",
    "        self.backbone.classifier = self.classifier_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = EfficientNetB0_Phase2(len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded54bbf-048f-488a-8ce8-1725dd832664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dict from Phase 1\n",
    "LOAD_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_MODEL\\EfficientNetB0_Phase1_CutMix_GridMask.pth\"\n",
    "if os.path.exists(LOAD_PATH):\n",
    "    model.load_state_dict(torch.load(LOAD_PATH, map_location=DEVICE))\n",
    "    print(f\"âœ… Loaded model from: {LOAD_PATH}\")\n",
    "else:\n",
    "    print(f\"âŒ Error: Phase 1 model not found at {LOAD_PATH}. Please run Phase 1 training first.\")\n",
    "    exit() # Exit if Phase 1 model is not found\n",
    "\n",
    "# Now, unfreeze all layers in the entire model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# --- Loss Function and Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05) # Lower label smoothing for fine-tuning\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829c3d8-e5a6-4735-9a12-94457d02e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Learning Rate Logger ---\n",
    "class LearningRateLogger:\n",
    "    def __init__(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def on_epoch_end(self, epoch):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr = param_group['lr']\n",
    "            print(f\"ðŸ“‰ Learning rate at epoch {epoch+1}: {lr:.6f}\")\n",
    "\n",
    "lr_logger = LearningRateLogger(optimizer)\n",
    "\n",
    "# --- Compute class weights ---\n",
    "train_labels_for_weights = []\n",
    "for _, labels in train_loader:\n",
    "    train_labels_for_weights.extend(labels.cpu().numpy())\n",
    "\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(CLASSES)),\n",
    "    y=train_labels_for_weights\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights_array, dtype=torch.float).to(DEVICE)\n",
    "print(\"âœ… Computed class weights:\", class_weights_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8b44d-f278-4d3e-8051-60a3ea8b4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "best_val_accuracy = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
    "    for i, (inputs, labels) in enumerate(train_loader_tqdm):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Apply CutMix\n",
    "        inputs, mixed_labels = cutmix(inputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        if mixed_labels.dim() > 1 and mixed_labels.shape[1] > 1:\n",
    "            log_softmax_outputs = F.log_softmax(outputs, dim=1)\n",
    "            loss = F.kl_div(log_softmax_outputs, mixed_labels, reduction='batchmean')\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=running_loss/total_train, acc=correct_train/total_train)\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    y_true_val, y_pred_val = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\")\n",
    "        for inputs, labels in val_loader_tqdm:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            y_true_val.extend(labels.cpu().numpy())\n",
    "            y_pred_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "            val_loader_tqdm.set_postfix(loss=val_loss/total_val, acc=correct_val/total_val)\n",
    "\n",
    "\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = correct_val / total_val\n",
    "    print(f\"Epoch {epoch+1} Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    lr_logger.on_epoch_end(epoch)\n",
    "\n",
    "    # Early Stopping\n",
    "    if epoch_val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = epoch_val_acc\n",
    "        patience_counter = 0\n",
    "        SAVE_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_MODEL\\EfficientNetB0_Phase2_CutMix_GridMask.pth\"\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"âœ… Model saved at: {SAVE_PATH} (Best validation accuracy: {best_val_accuracy:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"Patience: {patience_counter}/{4}\")\n",
    "        if patience_counter >= 4:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e86e-cee0-46b3-8f04-74d200bd0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "print(\"\\nðŸ“Š Final Evaluation on Validation Set:\")\n",
    "model.eval()\n",
    "y_true_final, y_pred_final = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true_final.extend(labels.cpu().numpy())\n",
    "        y_pred_final.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true_final, y_pred_final, target_names=CLASSES))\n",
    "\n",
    "cm = confusion_matrix(y_true_final, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
