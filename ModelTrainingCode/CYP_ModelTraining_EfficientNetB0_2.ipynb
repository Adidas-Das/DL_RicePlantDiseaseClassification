{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499f5357-5b5c-49d9-a755-909cd2a222d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total images found: 24004\n",
      "✅ Train samples: 19203 | Val samples: 4801\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 181\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# 2. Load weights from Phase 1\u001b[39;00m\n\u001b[0;32m    180\u001b[0m MODEL_PATH_PHASE1_WEIGHTS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mADITYA DAS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMachine Learning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCP_MODEL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEfficientNetB0_Phase1_CutMix_GridMask_weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH_PHASE1_WEIGHTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ EfficientNetB0 Phase 1 Model weights loaded from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH_PHASE1_WEIGHTS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# 3. Unfreeze all layers for fine-tuning\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:660\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m    Reverse or permute the axes of an array; returns the modified array.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m \n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf2.10.1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model, load_model # load_model is not needed if only loading weights\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input # Needed to rebuild model\n",
    "from tensorflow.keras.applications import EfficientNetB0 # Needed to rebuild model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input \n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_DATASET\"\n",
    "CLASSES = [\"BLIGHT\", \"BLAST\", \"BROWNSPOT\", \"HEALTHY\"]\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 60 \n",
    "LEARNING_RATE = 1e-6 \n",
    "\n",
    "# === Load filepaths & labels ===\n",
    "all_filepaths, all_labels = [], []\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    aug_path = os.path.join(BASE_PATH, class_name, \"augmented\")\n",
    "    files = glob.glob(os.path.join(aug_path, \"*.jpg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.jpeg\")) + \\\n",
    "            glob.glob(os.path.join(aug_path, \"*.png\"))\n",
    "    all_filepaths.extend(files)\n",
    "    all_labels.extend([idx] * len(files))\n",
    "\n",
    "print(f\"✅ Total images found: {len(all_filepaths)}\")\n",
    "\n",
    "# === tf.data.Dataset ===\n",
    "filepaths_ds = tf.data.Dataset.from_tensor_slices(all_filepaths)\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(all_labels)\n",
    "ds = tf.data.Dataset.zip((filepaths_ds, labels_ds)).shuffle(len(all_filepaths), seed=SEED)\n",
    "\n",
    "train_size = int(0.8 * len(all_filepaths))\n",
    "train_ds = ds.take(train_size)\n",
    "val_ds = ds.skip(train_size)\n",
    "\n",
    "print(f\"✅ Train samples: {train_size} | Val samples: {len(all_filepaths) - train_size}\")\n",
    "\n",
    "# === Color Jitter ===\n",
    "def color_jitter(image):\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_hue(image, max_delta=0.05)\n",
    "    return tf.clip_by_value(image, 0.0, 255.0)\n",
    "\n",
    "# === GridMask ===\n",
    "def grid_mask(image, d_min=50, d_max=100, ratio=0.5):\n",
    "    h, w, _ = image.shape\n",
    "    d = tf.random.uniform([], d_min, d_max, dtype=tf.int32)\n",
    "    l = tf.cast(tf.cast(d, tf.float32) * ratio, tf.int32)\n",
    "\n",
    "    mask = tf.ones([h, w], dtype=tf.float32)\n",
    "\n",
    "    for i in range(0, h, d):\n",
    "        for j in range(0, w, d):\n",
    "            y1 = i\n",
    "            y2 = tf.minimum(i + l, h)\n",
    "            x1 = j\n",
    "            x2 = tf.minimum(j + l, w)\n",
    "\n",
    "            y_range = tf.range(y1, y2)\n",
    "            x_range = tf.range(x1, x2)\n",
    "            yy, xx = tf.meshgrid(y_range, x_range, indexing='ij')\n",
    "            indices = tf.stack([yy, xx], axis=-1)\n",
    "            indices = tf.reshape(indices, [-1, 2])\n",
    "\n",
    "            mask = tf.tensor_scatter_nd_update(\n",
    "                mask,\n",
    "                indices,\n",
    "                tf.zeros([(y2 - y1) * (x2 - x1)], dtype=tf.float32)\n",
    "            )\n",
    "\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    mask = tf.tile(mask, [1, 1, 3])\n",
    "    return image * mask\n",
    "\n",
    "# === Image Processor ===\n",
    "def process_img(filepath, label):\n",
    "    img = tf.io.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "\n",
    "    img = color_jitter(img)\n",
    "    img = grid_mask(img)\n",
    "\n",
    "    img = preprocess_input(img) \n",
    "\n",
    "    label = tf.one_hot(label, depth=len(CLASSES))\n",
    "    return img, label\n",
    "\n",
    "# === CutMix ===\n",
    "def cutmix(images, labels, alpha=1.0):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    img_h = tf.shape(images)[1]\n",
    "    img_w = tf.shape(images)[2]\n",
    "\n",
    "    lam = tfp.distributions.Beta(alpha, alpha).sample([batch_size])\n",
    "\n",
    "    rand_idx = tf.random.shuffle(tf.range(batch_size))\n",
    "    images2 = tf.gather(images, rand_idx)\n",
    "    labels2 = tf.gather(labels, rand_idx)\n",
    "\n",
    "    cut_rat = tf.math.sqrt(1. - lam)\n",
    "    cut_w = tf.cast(img_w, tf.float32) * cut_rat\n",
    "    cut_h = tf.cast(img_h, tf.float32) * cut_rat\n",
    "\n",
    "    cx = tf.random.uniform([batch_size], 0, tf.cast(img_w, tf.float32))\n",
    "    cy = tf.random.uniform([batch_size], 0, tf.cast(img_h, tf.float32))\n",
    "\n",
    "    x1 = tf.cast(cx - cut_w / 2, tf.int32)\n",
    "    y1 = tf.cast(cy - cut_h / 2, tf.int32)\n",
    "    x2 = tf.cast(cx + cut_w / 2, tf.int32)\n",
    "    y2 = tf.cast(cy + cut_h / 2, tf.int32)\n",
    "\n",
    "    x1 = tf.clip_by_value(x1, 0, img_w)\n",
    "    y1 = tf.clip_by_value(y1, 0, img_h)\n",
    "    x2 = tf.clip_by_value(x2, 0, img_w)\n",
    "    y2 = tf.clip_by_value(y2, 0, img_h)\n",
    "\n",
    "    def apply_cutmix(i):\n",
    "        img1 = images[i]\n",
    "        img2 = images2[i]\n",
    "        bbx1, bby1, bbx2, bby2 = x1[i], y1[i], x2[i], y2[i]\n",
    "\n",
    "        mask = tf.pad(\n",
    "            tf.zeros([bby2 - bby1, bbx2 - bbx1, 3]),\n",
    "            [[bby1, img_h - bby2],\n",
    "             [bbx1, img_w - bbx2],\n",
    "             [0, 0]],\n",
    "            constant_values=1.0\n",
    "        )\n",
    "        mask = 1.0 - mask\n",
    "        mixed = img1 * mask + img2 * (1.0 - mask)\n",
    "\n",
    "        area = tf.cast(bbx2 - bbx1, tf.float32) * tf.cast(bby2 - bby1, tf.float32)\n",
    "        lam_adjusted = 1.0 - (area / tf.cast(img_w * img_h, tf.float32))\n",
    "        new_label = lam_adjusted * labels[i] + (1.0 - lam_adjusted) * labels2[i]\n",
    "\n",
    "        return mixed, new_label\n",
    "\n",
    "    mixed_images, mixed_labels = tf.map_fn(\n",
    "        apply_cutmix,\n",
    "        tf.range(batch_size),\n",
    "        fn_output_signature=(tf.float32, tf.float32)\n",
    "    )\n",
    "\n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "# === Final Pipeline ===\n",
    "train_ds = train_ds.map(process_img).batch(BATCH_SIZE)\n",
    "train_ds = train_ds.map(lambda x, y: cutmix(x, y)).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(process_img).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# === EfficientNetB0 Model (Phase 2) ===\n",
    "# 1. Rebuild the exact same model architecture as Phase 1\n",
    "base_model = EfficientNetB0(input_shape=(224, 224, 3), weights=None, include_top=False) \n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False) # Important: keep training=False for BN in base_model during rebuild\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(len(CLASSES), activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# 2. Load weights from Phase 1\n",
    "MODEL_PATH_PHASE1_WEIGHTS = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_MODEL\\EfficientNetB0_Phase1_CutMix_GridMask_weights.h5\"\n",
    "model.load_weights(MODEL_PATH_PHASE1_WEIGHTS, by_name=True, skip_mismatch=True)\n",
    "print(f\"✅ EfficientNetB0 Phase 1 Model weights loaded from: {MODEL_PATH_PHASE1_WEIGHTS}\")\n",
    "\n",
    "# 3. Unfreeze all layers for fine-tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# === Learning rate logger ===\n",
    "class LearningRateLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = self.model.optimizer.lr\n",
    "        if hasattr(lr, '__call__'):\n",
    "            lr = lr(self.model.optimizer.iterations)\n",
    "        if hasattr(lr, 'numpy'):\n",
    "            lr = lr.numpy()\n",
    "        print(f\"📉 Learning rate at epoch {epoch+1}: {lr:.6f}\")\n",
    "\n",
    "# === Compute class weights ===\n",
    "y_train_int = np.argmax(np.concatenate([labels.numpy() for _, labels in train_ds.unbatch().batch(BATCH_SIZE)]), axis=1)\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(CLASSES)),\n",
    "    y=y_train_int\n",
    ")))\n",
    "print(\"✅ Computed class weights:\", class_weights)\n",
    "\n",
    "# === Train ===\n",
    "print(\"\\n🚀 Starting EfficientNetB0 Phase 2 Training (Fine-tuning)...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[EarlyStopping(patience=4, restore_best_weights=True), LearningRateLogger()],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# === Evaluate ===\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "print(\"\\n📊 Classification Report (Phase 2):\")\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=CLASSES).plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"EfficientNetB0 Phase 2 Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Save Weights of the fine-tuned model ===\n",
    "SAVE_PATH_WEIGHTS = r\"C:\\Users\\ADITYA DAS\\Desktop\\Machine Learning\\CP_MODEL\\EfficientNetB0_Phase2_CutMix_GridMask_weights.h5\"\n",
    "model.save_weights(SAVE_PATH_WEIGHTS)\n",
    "print(f\"✅ EfficientNetB0 Phase 2 Model weights saved at: {SAVE_PATH_WEIGHTS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
